Bây giờ.

Tôi chỉ muốn thảo luận thêm một chút về những gì chúng ta đã nói trước đây về hiện tượng overfitting (quá khớp) và underfitting (thiếu khớp), nhưng bây giờ tôi muốn nói về chúng dưới góc độ của bias (độ thiên lệch) và variance (phương sai), vì rất thường xuyên, đặc biệt nếu bạn làm việc trong một nhóm, bạn có thể nói một cách không chính thức về overfitting và underfitting, nhưng chúng thường được gọi là bias và variance.

Vì vậy, tôi chỉ muốn chắc chắn rằng bạn không chỉ hiểu overfitting và underfitting là gì và cách chúng ta có thể giảm bớt các vấn đề liên quan, mà còn có thể nói về chúng như bias và variance.

Không phải là vấn đề quá lớn khi gọi chúng theo cách này hay cách khác, nhưng tốt hơn hết là hiểu rằng bạn có cả hai.

Vậy nếu bạn có bias cao, điều đó có nghĩa là mô hình của bạn đang bị underfitting (thiếu khớp). Nếu bạn tưởng tượng mô hình của mình, bạn có thể hình dung là đường thẳng tốt nhất mà chúng ta đã nói đến trong hồi quy tuyến tính. Bạn có thể tưởng tượng rằng nó không phù hợp với dữ liệu một cách tốt. Thực tế là đường thẳng tốt nhất không gần các điểm dữ liệu. Bạn có thể nghĩ về nó như vậy.

Nó không bắt kịp đủ các mẫu để mô tả dữ liệu một cách chính xác và đưa ra dự đoán đúng. Vì vậy, khi làm việc với bộ dữ liệu của chúng ta, khi có dữ liệu huấn luyện và kiểm tra, hoặc một số người gọi là huấn luyện và đánh giá, tùy vào cách bạn gọi, nếu bạn có độ chính xác thấp cho cả dữ liệu huấn luyện và kiểm tra.

Vậy nếu bạn có mất mát cao, điều đó có nghĩa là bạn có bias cao hoặc có thể gọi nó là underfitting. Khi độ chính xác của cả dữ liệu huấn luyện và kiểm tra thấp, điều đó có nghĩa là bạn đang bị underfitting và có bias cao.

Bây giờ, ở phía ngược lại, đây là khi mô hình của bạn đã trừu tượng hóa quá nhiều phức tạp từ dữ liệu mà nó có, để nó không thể phản ứng tốt với dữ liệu mới.

Ví dụ về những chiếc xe tăng với khu rừng phía sau mà chúng ta sẽ nói đến sau trong bài giảng này. Nhưng chúng ta đã nói về điều này khá nhiều và đã thảo luận về một số chiến lược khác nhau để giảm variance, chủ yếu là giảm độ phức tạp của các mạng nơ-ron của chúng ta.

Nhưng thực sự điều quan trọng nhất là cố gắng có càng nhiều dữ liệu càng tốt. Vì vậy, nếu bạn có thể tăng kích thước dữ liệu của mình, đó thực sự là điều sẽ giúp giảm overfitting vì nó sẽ có nhiều dữ liệu hơn để trừu tượng hóa phức tạp từ.

Vậy chỉ cần nhớ rằng nếu bạn có bias cao, điều đó có nghĩa là bạn đang underfitting và bạn sẽ thấy điều đó trong kết quả của mình. Nếu cả dữ liệu huấn luyện và kiểm tra của bạn đều có độ chính xác thấp.

Bây giờ, ở phía ngược lại, bạn có thể có variance cao hoặc cái mà chúng ta gọi là overfitting, và đó là khi độ chính xác cao trong bộ dữ liệu huấn luyện của bạn, nhưng độ chính xác lại thấp trong bộ dữ liệu kiểm tra hoặc đánh giá của bạn.

Một vài ví dụ mà chúng ta sẽ thảo luận.

Đối với bias cao, khi bạn đang underfitting, chúng ta sẽ xem xét một chiếc xe tự lái và ví dụ về một giáo viên và học sinh. Và đối với overfitting, thực sự có một ứng dụng thực tế rất thú vị mà nó đã sai vì overfitting. Sau đó chúng ta sẽ xem xét khi một người bạn nói rằng họ không thích một bộ phim.

Đầu tiên là chiếc xe tự lái.

Bạn có thể tưởng tượng rằng nếu bạn có một chiếc xe tự lái và bạn không huấn luyện nó đủ lâu, vậy bạn không cho phép nó phát hiện đủ các mẫu, thì nó có thể chỉ cần một mẫu rất cơ bản như: "À, khi tôi thấy màu đen và trắng, đó là đường." Vậy là nó cứ đi theo đó.

Vậy thì sao nếu nó thấy một con ngựa vằn? Nếu duy nhất quy tắc mà nó học được là màu đen và trắng, thì nó sẽ bị underfitting. Nó cần phải phát hiện nhiều mẫu hơn là chỉ màu đen và trắng. Vì vậy bạn có thể nói nó đang underfitting và bạn có lẽ không muốn lái chiếc xe này trên đường.

Đặc biệt nếu bạn đi safari. Đây là một ví dụ về underfitting.

Vậy giả sử chúng ta có một giáo viên và ông ấy đã giải thích một số quy tắc khác nhau về toán học, giả sử, và học sinh thì đang ngủ, và khi giáo viên hỏi: "Tôi vừa nói gì vậy?" thì học sinh thực sự không nhận ra bất kỳ mẫu nào và không học được gì từ điều đó. Bạn có thể nói là học sinh đã underfitting.

Sau đây là một ứng dụng thực tế rất thú vị.

Một thời gian trước đây, người ta đã thử tạo ra một mạng nơ-ron, một bộ phân loại hình ảnh có thể phát hiện xe tăng và các phương tiện bọc thép. Và họ đã được cung cấp một bộ dữ liệu rất lớn. Thật kỳ lạ vì khi mạng nơ-ron đã được huấn luyện, họ chắc chắn rằng nó hoạt động. Nhưng khi họ thử thêm một số hình ảnh mới để dự đoán, họ phát hiện ra rằng nếu bất kỳ hình ảnh nào chứa cây, thì nó sẽ xác định đó là một chiếc xe tăng, dù có hay không.

Vấn đề ở đây là tất cả dữ liệu ban đầu mà họ cung cấp chỉ có xe tăng và phương tiện bọc thép, và chúng chỉ xuất hiện trong rừng hoặc xung quanh cây cối. Vấn đề là mạng nơ-ron đã overfitting vì nó trừu tượng hóa quá nhiều phức tạp do không có đủ sự đa dạng trong bộ dữ liệu.

Vậy trong ví dụ này, việc giảm độ phức tạp của mạng nơ-ron sẽ không giúp ích gì. Điều quan trọng là họ cần phải thêm nhiều hình ảnh đa dạng hơn, nơi có xe tăng và các phương tiện bọc thép, nhưng không có cây xung quanh.

Cuối cùng, đây là một ví dụ khác.

Giả sử một người bạn nói rằng họ không thích phim. Nếu bạn chỉ đơn giản trừu tượng hóa từ điều đó, bạn có thể nghĩ rằng, "Ồ, có nghĩa là họ không thích bất kỳ bộ phim nào."

Nhưng đó không phải là sự thật.

Bạn cần hỏi họ thêm câu hỏi về việc họ có thích phim khác không.

Vì vậy, việc chỉ lấy một mảnh thông tin là "họ không thích phim" và trừu tượng hóa thành một mẫu rằng "họ không thích bất kỳ bộ phim nào" thì sẽ sai. Bạn cần phải hỏi thêm câu hỏi như "Bạn có thích phim hài không?" "Bạn có thích phim hành động không?" Và họ có thể sẽ nói "Ồ, tôi thích phim hài, nhưng tôi không thích phim hành động."

Khi đó bạn sẽ có thể trừu tượng hóa thêm các mẫu từ đó.

Vì vậy, trong ví dụ này, bạn cần thêm dữ liệu, nghĩa là hỏi thêm câu hỏi.

Vậy đây là một số ví dụ về các trường hợp thực tế của overfitting và underfitting.

Để giảm bias hoặc underfitting, điều bạn muốn làm là một số điều hữu ích là tăng độ phức tạp của mạng nơ-ron bằng cách thêm các lớp ẩn và các nút vào các lớp đó, và chỉ cần tăng số lượng huấn luyện, ví dụ như số lượng epoch.

Điều này sẽ giúp cải thiện độ chính xác của quá trình huấn luyện và độ chính xác kiểm tra.

Về việc giảm variance, một điều quan trọng là giảm độ phức tạp của mạng nơ-ron của bạn. Điều này thường rất hữu ích, vì nó sẽ không trừu tượng quá nhiều các mẫu phức tạp mà có thể không tồn tại trong thực tế.

Điều rất quan trọng nữa là đảm bảo bạn có càng nhiều dữ liệu càng tốt trong bộ dữ liệu huấn luyện. Và bạn cũng có đủ dữ liệu trong bộ kiểm tra hoặc bộ đánh giá của mình để đảm bảo bạn không bị overfitting.

Nếu bạn không thể có thêm dữ liệu, thì nếu không, bạn có thể thử tăng cường dữ liệu và chúng ta sẽ nói về điều này sau.

Bạn cũng có thể thêm dropout vào các lớp của mình, điều này chúng ta đã thảo luận trước đó.

Về dropout, điều quan trọng là khi bạn có mạng nơ-ron, nó sẽ làm giảm độ sáng của một số nút. Mỗi lần đi qua một epoch, nó sẽ chọn ngẫu nhiên một tỷ lệ phần trăm các nút và không áp dụng trọng số của chúng.

Điều này giúp tạo thêm một chút ngẫu nhiên hoặc bạn có thể gọi đó là stochastic.

